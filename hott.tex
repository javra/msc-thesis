This chapter shall serve to provide the reader with the necessary basic knowledge
about homotopy type theory.
Most of this knowledge was gathered and written up during the ``special year 
on univalent foundations'' which took place in the years 2012 and 2013
at the Institute for Advanced Study in Princeton.
It resulted in the collaborative effort to write and publish a first \emph{book}
on homotopy type theory~\cite{hottbook} which is still being improved and open
for suggestions at GitHub.~\footnote{\url{https://github.com/HoTT/book}}
My description of homotopy type theory will stick to the notation and terminology
used in this book.

Furthermore, I will not make the effort to distinguish between what elements of
the theory were there in earlier approaches to intensional type theory,
most prominently the one of Per Martin-L\"of~\cite{martin-lof1}, as this would
defy the purpose of a concise introduction to the current ``state of the art''.
%TODO this sounds wrong and pretentious?

\section{Some Basic Non-Dependent Type Theory}

A type theoretical foundation of mathematics uses \textbf{Types} wherever,
in an approach based on set theory and predicate logic, sets and propositions
are used.
Homotopy type theory adds to this logical interpretation and set interpretation
the point of view of a topological space or its homotopy type.
\textbf{Objects} (or \textbf{instances}) of a type thus correspond to elements of
a set, to proofs of a proposition, as well as to points in a space.

The judgment that that some object $a$ is an instance of a type $A$ will be written
as $a : A$.
Opposed to set theory it is always a priori determined, what type some constructed
object will be an instance of, and this type is, up to definitional equality of
types, fixed.
If an object or a type can be written in two different ways, we will express the
fact that two expressions coincide using ``$\equiv$'' (since ``$=$'' will later
denote propositional equality).
Likewise, ``$:\equiv$'' is the notation for abbreviating the the right hand side
by the expression on the left hand side.
It is important to note that it is decidable to check whether $a \equiv b$ holds
for two given terms $a$ and $b$.

Types in homotopy type theory are organized in \textbf{universes}.
For every $i \in \mathbb{N}$ we assume to have a universe $\UU_i$ which is itself,
as an object, contained in the universe $\UU_{i+1}$.
In this way, all types, including the universes, can be seen as objects in some
greater type.
Often, it is assumed that universes are \emph{cumulative} in the sense that if
$A : \UU_i$, then $A : \UU_{i+1}$ (and thus, $A : \UU_j$ for every $j \geq i$).
Since this entails some computational difficulties for theorem provers, the
language Lean will not incorporate universe cumulativity.
A replacement for the cumulativity is an inductively defined lifting function
$\UU_i \to \UU_{i+1}$.
In the following, I will most of the time leave the index of a universe implicit
and just denote it by $\UU$. This means to say that these definitions are applicable
to all (combinations of) universe indices.
The reason for the need of multiple universes is that a system that simply assumed
that $\UU : \UU$ would be inconsistent.

We will now take a look at some of the non-dependent type formers, some of which
will later be extended  to dependent ones.
We will introduce these type formers by giving semi-formal rules for the formation
of the type, the introduction of the type's instances and for their elimination.

The most basic type is the type $A \to B$ of \textbf{non-dependent} functions between two
types $A, B : \UU$.
The inference rules that come with it are exactly those known from types $\lambda$-calculus:
\begin{equation}
\begin{gathered}
\inferrule*[left=$\to$-Form]{A,B : \UU}{A \to B : \UU} \qquad
\inferrule*[left=$\to$-Intro]{a : A \vdash \Phi[a/x] : B}{(\lambda x. \Phi) : A \to B} \\
\inferrule*[left=$\to$-Elim]{f : A \to B \\ a : A}{f(a) : B}
\end{gathered}
\end{equation}
Here, $\Phi$ is a term that may have $x$ as a free variable.
$\Phi[a/x]$ denotes the replacement by every appearance of $x$ by $a$.
Of course, we have the rules of $\eta$-conversion and $\beta$-reduction:
\begin{equation} \label{eq:eta-beta}
\begin{aligned}
\inferrule*[left=$\eta$]{f : A \to B}{(\lambda x. f(x)) \equiv f} \qquad
\inferrule*[left=$\beta$]{(\lambda x. \Phi) : A \to B \\ a : A}
	{(\lambda x. \Phi)(a) \equiv \Phi[a/x]}
\end{aligned}
\end{equation}
These definitional will from now on be used ``silently'' to replace subterms.
In the logic interpretation of HoTT, function types model implication of propositions
while in the set and topology interpretation they represent (arbitrary resp.
continuous) maps.

One important special case of non-dependent function types are those of the form
$A \to \UU$ for a type $A : \UU$.
We call it the type of \textbf{type families} indexed by $A$.
With propositions as types, these represent propositions that depend on a variable
$x : A$.
Topologically, assigning to each point of a space another space ``above'' it
in a continuous fashion reflects the notion of a \emph{fibration}.

Especially when thinking of types modeling propositions, it is important to find
types that correspond to to the absolute truth values true and false.
A false statement should not be provable, so it should be represented by the
\textbf{empty type} $\emptytype$ which has no introduction rule at all:
\begin{equation*}
\inferrule*[left=$\emptytype$-Form]{ }{\emptytype : \UU} \qquad
\inferrule*[left=$\emptytype$-Elim]{C : \emptytype \to \UU \\ x : \emptytype}
	{\ind_\emptytype(C,x) : C(x)}
\end{equation*}
Here, $\ind_0$ stands for ``induction''.
The name indicates that $\emptytype$ is generated \emph{inductively} on an
empty collection of constructors.
The rule asserts that we can infer every possible statement once we constructed
an instance of $\emptytype$ (``ex falso quodlibet'').
Just like for every induction rule we will state in the rest of this chapter,
we can receive a non-dependent version of the rule, called \emph{recursion
rule}, by assuming $C$ to be a constant type family or, in other words, a type
$A : \UU$:
\begin{equation*}
\rec_\emptytype(A, x) :\equiv \ind_\emptytype((\lambda y. A), x) : A \text{.}
\end{equation*}

The type corresponding to ``true'' is the \textbf{unit type} $\unit$
which provides exactly one way of constructing an instance of it:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\unit$-Form]{ }{\unit : \UU} \qquad
\inferrule*[left=$\unit$-Intro]{ }{\star : \unit} \\
\inferrule*[left=$\unit$-Elim]{C : \unit \to \UU \\ p : C(\star) \\ x : \unit}
	{\ind_\unit(C,p,x) : C(x)}
\end{gathered}
\end{equation*}
The elimination rule can be thought of ensuring that we can prove a statement
about an arbitrary element of $\unit$ by just proving  it for the constructor
$\star$.
Additionally to the rule, we furthermore specify the behavior of the induction
on the constructor itself, by saying that $\ind_\unit(C,p,\star) \equiv p$.
In a set theoretic context, $\unit$ would be a (or ``the'') singleton, from the
topological point of view it stands for a contractible space.
Again, if we set $C(x) :\equiv A$ for some type $A : \UU$, we obtain a
non-dependent recursor $\rec_\unit(A) : A \to \unit \to A$, selecting
for each point $a : A$ the function that maps to $a$.

Looking at the type of some of the recursors, for example $\rec_\unit$, before
giving all their arguments, we struggle to express their type using only
non-dependent functions, since e.g. $\rec_\unit(A)$ does not have the same type
for every choice of $A : \UU$.
This is where dependent functions come into play.

\section{Dependent Functions and Products}

\textbf{Dependent Functions}, also called $\Pi$\textbf{-types}, are the core of
dependent type theory.
Opposed to a non-dependent function $f : A \to B$ between two types $A, B : \UU$,
which returns an instance of $B$ when applied to whatever instance of $A$,
the return type of a dependent function on a type family $B : A \to \UU$ is
$B(a)$  when the function is evaluated at some instance $a : A$.
Of course, we can rediscover non-dependent function types as $\Pi$-types on
constant type families.
We write $\prod_{(a : A)} B(a)$ for the type of dependent functions on the type
family $B : A \to \UU$.
Since to construct such a dependent function, we need to give an element of
$B(a)$ for \emph{every} $a : A$, we can think of $\prod_{(a : A)} B(a)$ as the
statement ``For all $a : A$, the statement $B(a)$ holds''.
In the topological interpretation, we can say that this corresponds to giving
a point in each fiber of the fibration $B : A \to \UU$ varying continuously
on the chosen $a : A$.
this is called a \emph{section} of the fibration.
The rules to form the type of $\Pi$-types and to introduce and apply dependent
functions generalize the rules for non-dependent functions as follows:
\begin{equation}
\begin{gathered}
\inferrule*[left=$\Pi$-Form]{A : \UU \\ B : A \to \UU}
	{\textstyle{(\prod_{(a : A)} B(a))} : \UU} \qquad
\inferrule*[left=$\Pi$-Intro]{a : A \vdash \Phi[a/x] : B(a)}
	{(\lambda x. \Phi) : \textstyle{\prod_{(a : A)} B(a)}} \\
\inferrule*[left=$\Pi$-Elim]{f : \textstyle{\prod_{(a : A)} B(a)} \\ a : A}
	{f(a) : B(a)}
\end{gathered}
\end{equation} %TODO talk about predicativity?
Again, we have the rules for $\beta$-reduction and $\eta$-conversion like in
the non-dependent case~(\ref{eq:eta-beta}), yielding judgmental equalities
$(\lambda x. f (x)) \equiv f$ and $(\lambda x. \Phi)(a) \equiv \Phi[a/x]$.

Having defined $\Pi$-types we are able to state the recursor for other basic
actually non-dependent type formers: Product and coproduct types.
These take the type theoretic role of conjunction and disjunction of propositions,
and of cartesian products and and disjoint unions of sets or topological
spaces.
The inference rules for \textbf{product types} are the following:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\times$-Form]{A, B : \UU}{A \times B : \UU} \qquad
\inferrule*[left=$\times$-Intro]{a : A \\ b : B}{(a, b) : A \times B} \\
\inferrule*[left=$\times$-Elim]{C : A \times B \to \UU \\
	p: \textstyle{\prod_{(a : A)} \prod_{(b : B)} C((a,b))} \\ x : A \times B}
	{\ind_{A \times B}(C, p, x) : C(x)}
\end{gathered}
\end{equation*}
with the definitional equality $\ind_{A \times B}(C, p, (a, b)) \equiv p(a, b)$.
Note that the type of $\ind_{A \times B}$ can now be expressed as
\begin{equation*}
\prod_{C : A \times B \to \UU} \left( \prod_{a : A} ~ \prod_{b : B} C((a,b)) \right)
	\to \prod_{x : A \times B} C(x) \text{.}
\end{equation*}
The first and second projection of an instance $x : A \times B$ are then simply
defined by
\begin{align*}
\pr_1(x) &:\equiv \ind_{A \times B}((\lambda y. A), (\lambda a. \lambda b. a), x) \\
\pr_2(x) &:\equiv \ind_{A \times B}((\lambda y. A), (\lambda a. \lambda b. b), x) \text{,}
\end{align*}
yielding $\pr_1((a, b)) \equiv a$ and $\pr_2((a, b)) \equiv b$ judgmentally.
An informal way of stating the meaning of $\times$\textsc{-Elim} would be:
``To show a statement about all instances of a product type, is suffices to
prove it for all pairs''.

Dually to products we define the \textbf{coproduct} or \textbf{sum} of two types
by giving the following rules:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$+$-Form]{A : \UU \\ B : \UU}{A + B : \UU} \\[.7em]
\inferrule*[left=$+$-Intro1]{a : A}{\inl(a) : A + B} \qquad
\inferrule*[left=$+$-Intro2]{b : B}{\inr(b) : A + B} \\[.7em]
\inferrule*[left=$+$-Elim]
	{C : (A + B) \to \UU \\  p : \textstyle{\prod_{(a : A)} C(\inl(a))}
		\\ q : \textstyle{\prod_{(b : B)} C(\inr(b))} \\ x : A + B}
	{\ind_{A + B}(C, p, q, x) : C(x)}
\end{gathered}
\end{equation*}
Note that this is the first type former for which there is more than just one
introduction rule.
Likewise there is more than one ``base case'' to prove to use the induction rule.

Going back and looking at the product type, we recognize that we can, just as
for the function type, find a more general, dependent version, the
\textbf{dependent product type} or $\Sigma$\textbf{-type}.
The gain of generality consists of the fact that, for the pairs that make up the
type, the type of their second component may depend on the concrete value of the
first component.
This can be used to model existentially quantified statements like
``there exists an $a : A$ such that $B(a)$ holds.''
Topologically, the $\Sigma$-type of a fibration $B : A \to \UU$ represents the
\emph{total space} of $B$.
The first projection of a dependent pair corresponds to the projection of a point
in a fiber onto its base.
(This is the map which topologists would traditionally refer to as ``the fibration''.)
The inference rules for dependent products are:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\Sigma$-Form]{A : \UU \\ B : A \to \UU}
	{\textstyle{(\sum_{(a : A)} B(a))} : \UU} \qquad
\inferrule*[left=$\Sigma$-Intro]{a : A \\ b : B(a)}
	{(a, b) : \textstyle{(\sum_{(a : A)} B(a))}} \\[.7em]
\inferrule*[left=$\Sigma$-Elim]
	{C : (\textstyle{(\sum_{(a : A)} B(a))}) \to \UU \\
		p : \textstyle{\prod_{(a : A)} \prod_{(b : B(a))}} C((a,b)) \\
		x : \textstyle{(\sum_{(a : A)} B(a))}}
	{\ind_{(\sum_{(a : A)} B(a))}(C, p, x) : C(x)}
\end{gathered}
\end{equation*}
Again, we assume the definitional equality
\begin{equation*}
\ind_{(\sum_{(a : A)} B(a))}(C, p, (a, b)) \equiv p(a, b) \text{.}
\end{equation*}
We can recover non-dependent products by setting $B$ to be a constant type family.

Product types, $\Sigma$-types, coproduct types, the unit type and the empty type
all are examples for the larger class of \textbf{inductive types}.
I will abstain from giving the general definition of inductive types and
inductive types families and again refer to definitions in either the HoTT book~\cite{hottbook}
and the introduction of inductive families by Peter Dybier~\cite{inductive-families},
which provided the blueprint for the implementation in Lean.
Instead, I will another a common example for an inductive type:

Just as the unit type was defined inductively on its constructor $\star$ and
the coproduct on two constructor $\inl$ and $\inr$, we can obtain the
\textbf{natural numbers} $\N$ as the inductive type of a zero element
$0 : \N$ and the successor function $S : \N \to \N$.
These data yield, besides the obvious introduction rules, the following well-known
elimination rule:
\begin{equation*}
\inferrule*[left=$\N$-Elim]
	{C : \N \to \UU \\ p : C(0) \\ q : \textstyle{\prod_{(n : \N)}} C(n) \to C(S(n)) \\
		x : \N}
	{\ind_\N(C, p, q, x) : C(x)}
\end{equation*}
The judgmental equalities of the rule are $\ind_\N(C, p, q, 0) \equiv p$ and
the recursive equation
\begin{equation*}
\ind_\N(C, p, q, S(x)) \equiv q(x, \ind_\N(C, p, q, x)) \text{.}
\end{equation*}
For a constant type family we get the non-dependent recursion
\begin{equation*}
\rec_\N(A) :\equiv \ind(\lambda x. A) : A \to (\N \to A \to A) \to \N \to A \text{,}
\end{equation*}
which is exactly the intuitive way to define a function $\N \to A$ by recursion.
If we were to define what it means for a natural number to be odd, we could do
this by
\begin{equation*}
\isodd :\equiv \rec_\N(\UU, \emptytype, (\lambda n. \lambda A. A \to \emptytype)) : \N \to \UU \text{,}
\end{equation*}
where $A \to \emptytype$ is inhabited if $A$ is not, and thus models the negation
of statements.
For example, this gives us the statement that the number one is odd, witnessed by
the following term:
\begin{align*}
(\lambda x. x) :~ & \emptytype \to \emptytype \\
 &\equiv \ind_\N((\lambda x. \UU), \emptytype, (\lambda n. \lambda A. A \to \emptytype), 0)
  \to \emptytype\\
 &\equiv \ind_\N((\lambda x. \UU), \emptytype, (\lambda n. \lambda A. A \to \emptytype), S(0))\\
 &\equiv \isodd(S(0)) \text{.}
\end{align*}

\section{Propositional Equality}

So far, all equalities were judgmental or definitional:
They resulted from defining new notations and from the judgmental equalities that
come with each induction rule.
As mentioned before, it is decidable to check two terms for equality.
But this means that with this kind of equality, we will not be able to reason
about undecidable equality statements, or express equality \emph{inside} the
theory.
Since in the logical interpretation of type theory, every statement should be
represented by a type, so should the equality of two objects of the same type.
This is why we introduce the \textbf{equality type} or \textbf{identity type}
as our next type.
It is obvious that for a type $A : \UU$ and two objects $a, b : A$ there should
be a type $a =_A b$ of which we need so construct an instance to show that $a$
and $b$ are ``equal'' in some sense.
But what should the introduction and the elimination rule for such a type look
like?
It turns out that it should be the relation that is defined inductively on the
witnesses for its reflexivity:
\begin{equation*}
\begin{gathered}
\inferrule*[left={$=$-Form}]{A : \UU \\ a, b : A}{a =_A b : \UU} \qquad
\inferrule*[left={$=$-Intro}]{A : \UU \\ a : A}{\refl_a : a =_A a} \\[.7em]
\inferrule*[left={$=$-Elim}]
	{C : \textstyle{\prod_{(a,b : A)} (a =_A b) \to \UU} \\
		c : \textstyle{\prod_{(a : A)}} C (a, a, \refl_a) \\
		a, b : A \\ p : a =_A b}
	{\ind_{=_A}(C, c, a, b, p) : C(x, y, p)}
\end{gathered}
\end{equation*}
The introduction rule gives us a canonical proof for the equality of two
definitionally equal objects.
The recursor says that to prove a statement about all pairs of points in a type
and all equalities between them, it suffices to show it for reflexive case and
the canonical equality proof $\refl$.
An elimination rule equivalent to the \emph{unbased equality induction} or
\emph{J-rule} stated above is the following \emph{based equality induction} where
we fix the start point of each equality we reason about:
\begin{equation*}
\inferrule*[left={Based-$=$-Elim}]
	{a : A \\ C : \textstyle{\prod_{(b : A)}} (a =_A b) \to \UU \\
		c : C(a, \refl_a) \\
		b : A \\ p : a =_A b}
	{\ind'_{=_A}(a, C, c, b, p) : C(b, p)}
\end{equation*}
Both elimination rules are assumed to yield judgmental equalities when applied
to the constructor $\refl$ itself:
\begin{align*}
\ind_{=_A}(C, c, a, a, \refl_a) &\equiv c(a) \text{ and } \\
\ind'_{=_A}(a, C, c, a, \refl_a) &\equiv c \text{.}
\end{align*}
We will see that for the topological interpretation of types, the identity type
should not necessarily be seen as representing equality of points but rather
\emph{paths between points}.

Equal objects should be indiscernible in the sense that every property $C : A \to \UU$
that is provable for some $a : A$ by giving an instance of $C(a)$ should also be
provable for $b : A$, given an equality $p : a =_A b$.
As a first lemma about equality we prove that this is indeed the case.
(Note that the distinction between a definition and a lemma or theorem together
with its proof is less clear in type theory than it is for set based mathematics.)

\begin{lemma}[Transport.] \label{thm:transport-hott}
Let $C : A \to \UU$ be a type family, $a , b : A$ equal by $p : a =_A b$.
Then, for each $c : C(a)$, we obtain an object $p_*(c) : C(b)$.
We call this the \textbf{transport} $c$ along the path $p$.
\end{lemma}

\begin{proof}
We can use (based or unbased) path induction to reduce the statement to the one
where $p \equiv \refl_a$.
In this case, we simply to chose $p_*(c) :\equiv c$.
Formally, we define
\begin{equation*}
p_*(c) :\equiv \ind'_{=_A}(a, (\lambda b. \lambda p. C(b)), c, b, p) \text{.}
\end{equation*}
\end{proof}
In the statement of the lemma, the listed precondition should be thought of as
an iterated $\Pi$-type, so that the full statement is of the type
\begin{equation*}
\prod_{C : A \to \UU} ~ \prod_{a, b : A} ~ \prod_{p : a =_A b} C(a) \to C(b) \text{.}
\end{equation*}

We have seen that the propositional equality we defined above is, by its constructor
reflexive.
But since equality should be an equivalence relation, we have to prove its
symmetry and transitivity, or, in the language of paths, provide the inverse and
concatenation of paths.

\begin{defn}[Inverse paths.]
Let $A : \UU$ and $a, b : A$.
For every path $p : a =_A b$, there is a path $p\inv : b =_A a$ such that
$\refl_a\inv \equiv \refl_a$ for every $a : A$.
\end{defn}

\begin{proof}
By path induction, it suffices to provide $\refl_a\inv : a =_A a$, which we provide
by giving $\refl_a$. Formally:
$p\inv :\equiv \ind'_{=_A}(a, (\lambda b. \lambda p. b =_A a), \refl_a, b, p)$.
\end{proof}

\begin{defn}[Concatenation of paths.]
For a type $A : \UU$, $a, b, c : A$ and paths $p : a = b$ and $q : b = c$ there
is a path $p \ct q : a = c$ which can be chosen in a way such that
$\refl_a \ct \refl_a \equiv \refl_a$.
\end{defn}

\begin{proof}
We again apply induction on the equalities involved to end up having only to
specify an instance of $a = a$ which we choose to be $\refl_a$.
I will from now on abstain from giving the type families and applications
of the equality elimination rule explicitly.
More formal proofs for these definitions can be found in any formalization or
in the HoTT book~\cite{hottbook}.
\end{proof}

We see that this inversion and concatenation are exactly the operations which are
part of a groupoid.
It turns out that they also fulfill the defining properties of a groupoid:

\begin{defn}[Groupoid laws.]
Let $A : \UU$, $a, b, c, d : A$ and $p : a = b$, $q : b = c$ and $r : c = d$.
Then,
\begin{itemize}
\item $p = p \ct \refl_b = \refl_a \ct p$,
\item $p\inv \ct p = \refl_b$, $p \ct p\inv = \refl_a$,
\item $(p\inv)\inv = p$ and
\item $p \ct (q \ct r) = (p \ct q) \ct r$.
\end{itemize}
\end{defn}

\begin{proof}
We can prove all these by applying path induction to all the three paths involved.
\end{proof}

Note that all these propositional equalities are \emph{between equalities} and,
if we wrote the first equation mentioned in the previous definition noting the
type it was in, it would be $p =_{a =_A b} p \ct \refl_b$.
We call these equalities \textbf{2-paths} or \textbf{2-dimensional paths}.
These make the equality in a type an $\infty$-groupoid.

To be a suitable notion of equality, it should be respected by functions in the
sense that for a function $f : A \to B$ and an equality $p : a = b$ in its domain
we should be able to obtain an equality $f(a) = f(b)$ in the codomain.
This is indeed the case, which we can prove by induction on the equality:
\begin{lemma}
Let $A, B : \UU$, $f : A \to B$, and $a, b : A$. Then, there is a function
$\ap_f : (a = b) \to (f(a) = f(b))$ such that $\ap_f(\refl_a) \equiv \refl_{f(a)}$.
\end{lemma}

\section{Truncated Types}

\section{Equivalences and univalence}
