This chapter shall serve to provide the reader with the necessary basic knowledge
about homotopy type theory.
Most of this knowledge was gathered and written up during the ``special year 
on univalent foundations'' which took place in the years 2012 and 2013
at the Institute for Advanced Study in Princeton.
It resulted in the collaborative effort to write and publish a first \emph{book}
on homotopy type theory~\cite{hottbook} which is still being improved and open
for suggestions at GitHub.~\footnote{\url{https://github.com/HoTT/book}}
My description of homotopy type theory will stick to the notation and terminology
used in this book.

Furthermore, I will not make the effort to distinguish between what elements of
the theory were there in earlier approaches to intensional type theory,
most prominently the one of Per Martin-L\"of~\cite{martin-lof1}, as this would
defy the purpose of a concise and coherent introduction to the current ``state of the art''
of homotopy type theory.

\section{Some Basic Non-Dependent Type Theory}

A type theoretical foundation of mathematics uses \textbf{Types} wherever,
in an approach based on set theory and predicate logic, sets and propositions
are used.
Homotopy type theory adds to this logical interpretation and set interpretation
the point of view of a topological space or its homotopy type.
\textbf{Objects} (or \textbf{instances}) of a type thus correspond to elements of
a set, to proofs of a proposition, as well as to points in a space.

The judgment that that some object $a$ is an instance of a type $A$ will be written
as $a : A$.
Opposed to set theory it is always a priori determined, what type some constructed
object will be an instance of, and this type is, up to definitional equality of
types, fixed.
If an object or a type can be written in two different ways, we will express the
fact that two expressions coincide using ``$\equiv$'' (since ``$=$'' will later
denote propositional equality).
Likewise, ``$:\equiv$'' is the notation for abbreviating the the right hand side
by the expression on the left hand side.
It is important to note that it is decidable to check whether $a \equiv b$ holds
for two given terms $a$ and $b$.

Types in homotopy type theory are organized in \textbf{universes}.
For every $i \in \mathbb{N}$ we assume to have a universe $\UU_i$ which is itself,
as an object, contained in the universe $\UU_{i+1}$.
In this way, all types, including the universes, can be seen as objects in some
greater type.
Often, it is assumed that universes are \emph{cumulative} in the sense that if
$A : \UU_i$, then $A : \UU_{i+1}$ (and thus, $A : \UU_j$ for every $j \geq i$).
Since this entails some computational difficulties for theorem provers, the
language Lean will not incorporate universe cumulativity.
A replacement for the cumulativity is an inductively defined lifting function
$\UU_i \to \UU_{i+1}$.
In the following, I will most of the time leave the index of a universe implicit
and just denote it by $\UU$. This means to say that these definitions are applicable
to all (combinations of) universe indices.
The reason for the need of multiple universes is that a system that simply assumed
that $\UU : \UU$ would be inconsistent.

We will now take a look at some of the non-dependent type formers, some of which
will later be extended  to dependent ones.
We will introduce these type formers by giving semi-formal rules for the formation
of the type, the introduction of the type's instances and for their elimination.

The most basic type is the type $A \to B$ of \textbf{non-dependent} functions between two
types $A, B : \UU$.
The inference rules that come with it are exactly those known from types $\lambda$-calculus:
\begin{equation}
\begin{gathered}
\inferrule*[left=$\to$-Form]{A,B : \UU}{A \to B : \UU} \qquad
\inferrule*[left=$\to$-Intro]{a : A \vdash \Phi[a/x] : B}{(\lambda x. \Phi) : A \to B} \\
\inferrule*[left=$\to$-Elim]{f : A \to B \\ a : A}{f(a) : B}
\end{gathered}
\end{equation}
Here, $\Phi$ is a term that may have $x$ as a free variable.
$\Phi[a/x]$ denotes the replacement by every appearance of $x$ by $a$.
Of course, we have the rules of $\eta$-conversion and $\beta$-reduction:
\begin{equation} \label{eq:eta-beta}
\begin{aligned}
\inferrule*[left=$\eta$]{f : A \to B}{(\lambda x. f(x)) \equiv f} \qquad
\inferrule*[left=$\beta$]{(\lambda x. \Phi) : A \to B \\ a : A}
	{(\lambda x. \Phi)(a) \equiv \Phi[a/x]}
\end{aligned}
\end{equation}
These definitional equalities will from now on be used ``silently'' to replace subterms.
In the logic interpretation of HoTT, function types model implication of propositions
while in the set and topology interpretation they represent (arbitrary resp.
continuous) maps.

One important special case of non-dependent function types are those of the form
$A \to \UU$ for a type $A : \UU$.
We call it the type of \textbf{type families} indexed by $A$.
With propositions as types, these represent propositions that depend on a variable
$x : A$.
Topologically, assigning to each point of a space another space ``above'' it
in a continuous fashion reflects the notion of a \emph{fibration}.

Especially when thinking of types modeling propositions, it is important to find
types that correspond to to the absolute truth values true and false.
A false statement should not be provable, so it should be represented by the
\textbf{empty type} $\emptytype$ which has no introduction rule at all:
\begin{equation*}
\inferrule*[left=$\emptytype$-Form]{ }{\emptytype : \UU} \qquad
\inferrule*[left=$\emptytype$-Elim]{C : \emptytype \to \UU \\ x : \emptytype}
	{\ind_\emptytype(C,x) : C(x)}
\end{equation*}
Here, $\ind_0$ stands for ``induction''.
The name indicates that $\emptytype$ is generated \emph{inductively} on an
empty collection of constructors.
The rule asserts that we can infer every possible statement once we constructed
an instance of $\emptytype$ (``ex falso quodlibet'').
Just like for every induction principle we will state in the rest of this chapter,
we can obtain a non-dependent version of the rule, called \emph{recursion
rule}, by assuming $C$ to be a constant type family or, in other words, a type
$A : \UU$:
\begin{equation*}
\rec_\emptytype(A, x) :\equiv \ind_\emptytype((\lambda y. A), x) : A \text{.}
\end{equation*}

The type corresponding to ``true'' is the \textbf{unit type} $\unit$
which provides exactly one way of constructing an instance of it:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\unit$-Form]{ }{\unit : \UU} \qquad
\inferrule*[left=$\unit$-Intro]{ }{\star : \unit} \\[.7em]
\inferrule*[left=$\unit$-Elim]{C : \unit \to \UU \\ p : C(\star) \\ x : \unit}
	{\ind_\unit(C,p,x) : C(x)}
\end{gathered}
\end{equation*}
The elimination rule can be thought of ensuring that we can prove a statement
about an arbitrary element of $\unit$ by just proving  it for the constructor
$\star$.
Additionally to the rule, we furthermore specify the behavior of the induction
on the constructor itself, by saying that $\ind_\unit(C,p,\star) \equiv p$.
In a set theoretic context, $\unit$ would be a (or ``the'') singleton, from the
topological point of view it stands for a contractible space.
Again, if we set $C(x) :\equiv A$ for some type $A : \UU$, we obtain a
non-dependent recursor $\rec_\unit(A) : A \to \unit \to A$, selecting
for each point $a : A$ the function that maps to $a$.

Looking at the type of some of the recursors, for example $\rec_\unit$, before
giving all their arguments, we struggle to express their type using only
non-dependent functions, since e.g. $\rec_\unit(A)$ does not have the same type
for every choice of $A : \UU$.
This is where dependent functions come into play.

\section{Dependent Functions and Pairs}

\textbf{Dependent Functions}, also called $\Pi$\textbf{-types}, are the core of
dependent type theory.
Opposed to a non-dependent function $f : A \to B$ between two types $A, B : \UU$,
which returns an instance of $B$ when applied to whatever instance of $A$,
the return type of a dependent function on a type family $B : A \to \UU$ is
$B(a)$  when the function is evaluated at some instance $a : A$.
Of course, we can rediscover non-dependent function types as $\Pi$-types on
constant type families.
We write $\prod_{(a : A)} B(a)$ for the type of dependent functions on the type
family $B : A \to \UU$.
Since to construct such a dependent function, we need to give an element of
$B(a)$ for \emph{every} $a : A$, we can think of $\prod_{(a : A)} B(a)$ as the
statement ``For all $a : A$, the statement $B(a)$ holds.''
In the topological interpretation, we can say that this corresponds to giving
a point in each fiber of the fibration $B : A \to \UU$ varying continuously
on the chosen $a : A$.
this is called a \emph{section} of the fibration.
The rules to form the type of $\Pi$-types and to introduce and apply dependent
functions generalize the rules for non-dependent functions as follows:
\begin{equation}
\begin{gathered}
\inferrule*[left=$\Pi$-Form]{A : \UU_i \\ B : A \to \UU_j}
	{\textstyle{(\prod_{(a : A)} B(a))} : \UU_{max\{i,j\}}} \qquad
\inferrule*[left=$\Pi$-Intro]{a : A \vdash \Phi[a/x] : B(a)}
	{(\lambda x. \Phi) : \textstyle{\prod_{(a : A)} B(a)}} \\[.7em]
\inferrule*[left=$\Pi$-Elim]{f : \textstyle{\prod_{(a : A)} B(a)} \\ a : A}
	{f(a) : B(a)}
\end{gathered}
\end{equation}
Again, we have the rules for $\beta$-reduction and $\eta$-conversion like in
the non-dependent case~(\ref{eq:eta-beta}), yielding judgmental equalities
$(\lambda x. f (x)) \equiv f$ and $(\lambda x. \Phi)(a) \equiv \Phi[a/x]$.

Having defined $\Pi$-types we are able to state the recursor for other basic,
essentially non-dependent, type formers: Product and coproduct types.
These take the type theoretic role of conjunction and disjunction of propositions,
and of cartesian products and and disjoint unions of sets or topological
spaces.
The inference rules for \textbf{product types} are the following:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\times$-Form]{A, B : \UU}{A \times B : \UU} \qquad
\inferrule*[left=$\times$-Intro]{a : A \\ b : B}{(a, b) : A \times B} \\[.7em]
\inferrule*[left=$\times$-Elim]{C : A \times B \to \UU \\
	p: \textstyle{\prod_{(a : A)} \prod_{(b : B)} C((a,b))} \\ x : A \times B}
	{\ind_{A \times B}(C, p, x) : C(x)}
\end{gathered}
\end{equation*}
with the definitional equality $\ind_{A \times B}(C, p, (a, b)) \equiv p(a, b)$.
Note that the type of $\ind_{A \times B}$ can now be expressed as
\begin{equation*}
\prod_{C : A \times B \to \UU} \left( \prod_{a : A} ~ \prod_{b : B} C((a,b)) \right)
	\to \prod_{x : A \times B} C(x) \text{.}
\end{equation*}
The first and second projection of an instance $x : A \times B$ is then simply
defined by
\begin{align*}
\pr_1(x) &:\equiv \ind_{A \times B}((\lambda y. A), (\lambda a. \lambda b. a), x) : A \\
\pr_2(x) &:\equiv \ind_{A \times B}((\lambda y. A), (\lambda a. \lambda b. b), x) : B \text{,}
\end{align*}
yielding $\pr_1((a, b)) \equiv a$ and $\pr_2((a, b)) \equiv b$ judgmentally.
An informal way of stating the meaning of $\times$\textsc{-Elim} would be:
``To show a statement about all instances of a product type, is suffices to
prove it for all pairs''.

Dually to products we define the \textbf{coproduct} or \textbf{sum} of two types
by giving the following rules:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$+$-Form]{A : \UU \\ B : \UU}{A + B : \UU} \\[.7em]
\inferrule*[left=$+$-Intro1]{a : A}{\inl(a) : A + B} \qquad
\inferrule*[left=$+$-Intro2]{b : B}{\inr(b) : A + B} \\[.7em]
\inferrule*[left=$+$-Elim]
	{C : (A + B) \to \UU \\  p : \textstyle{\prod_{(a : A)} C(\inl(a))}
		\\ q : \textstyle{\prod_{(b : B)} C(\inr(b))} \\ x : A + B}
	{\ind_{A + B}(C, p, q, x) : C(x)}
\end{gathered}
\end{equation*}
Note that this is the first type former for which there is more than just one
introduction rule.
As a consequence, there is more than one ``base case'' to prove to use the induction rule.

Going back and looking at the product type, we recognize that we can, just as
for the function type, find a more general, dependent version, the
\textbf{dependent product type} or $\Sigma$\textbf{-type}.
The gain of generality consists of the fact that, for the pairs that make up the
type, the type of their second component may depend on the concrete value of the
first component.
This can be used to model existentially quantified statements like
``there exists an $a : A$ such that $B(a)$ holds.''
Topologically, the $\Sigma$-type of a fibration $B : A \to \UU$ represents the
\emph{total space} of $B$.
The first projection of a dependent pair corresponds to the projection of a point
in a fiber onto its base.
(This is the map which topologists would traditionally refer to as ``the fibration''.)
The inference rules for dependent products are:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\Sigma$-Form]{A : \UU \\ B : A \to \UU}
	{\textstyle{(\sum_{(a : A)} B(a))} : \UU} \qquad
\inferrule*[left=$\Sigma$-Intro]{a : A \\ b : B(a)}
	{(a, b) : \textstyle{(\sum_{(a : A)} B(a))}} \\[.7em]
\inferrule*[left=$\Sigma$-Elim]
	{C : (\textstyle{(\sum_{(a : A)} B(a))}) \to \UU \\
		p : \textstyle{\prod_{(a : A)} \prod_{(b : B(a))}} C((a,b)) \\
		x : \textstyle{(\sum_{(a : A)} B(a))}}
	{\ind_{(\sum_{(a : A)} B(a))}(C, p, x) : C(x)}
\end{gathered}
\end{equation*}
Again, we assume the definitional equality
\begin{equation*}
\ind_{(\sum_{(a : A)} B(a))}(C, p, (a, b)) \equiv p(a, b) \text{.}
\end{equation*}
We can recover non-dependent products by setting $B$ to be a constant type family.
The projections to the first and second component are defined similar to the ones
of non-dependent products for a dependent pair $x : \prod_{(a : A)} B(a)$:
\begin{align*}
\pr_1(x) &:\equiv \ind_{(\prod_{(a : A)} B(a))}((\lambda x. A),
	(\lambda a. \lambda b. a), x) \text{ and } \\
\pr_2(x) &:\equiv \ind_{(\prod_{(a : A)} B(a))}
	((\lambda x. B(\pr_1(x))), (\lambda a. \lambda b. b), x) \text{.}
\end{align*}

Product types, $\Sigma$-types, coproduct types, the unit type and the empty type
all are examples for the larger class of \textbf{inductive types}.
I will abstain from giving the general definition of inductive types and
inductive type families and again refer to definitions in either the HoTT book~\cite{hottbook}
and the introduction of inductive families by Peter Dybier~\cite{inductive-families},
which provided the blueprint for the implementation in Lean.
Instead, I will another a common example for an inductive type:

Just as the unit type was defined inductively on its constructor $\star$ and
the coproduct on two constructor $\inl$ and $\inr$, we can obtain the
\textbf{natural numbers} $\N$ as the inductive type of a zero element
$0 : \N$ and the successor function $S : \N \to \N$.
These data yield, besides the obvious introduction rules, the following well-known
elimination rule:
\begin{equation*}
\inferrule*[left=$\N$-Elim]
	{C : \N \to \UU \\ p : C(0) \\ q : \textstyle{\prod_{(n : \N)}} C(n) \to C(S(n)) \\
		x : \N}
	{\ind_\N(C, p, q, x) : C(x)}
\end{equation*}
The judgmental equalities of the rule are $\ind_\N(C, p, q, 0) \equiv p$ and
the recursive equation
\begin{equation*}
\ind_\N(C, p, q, S(x)) \equiv q(x, \ind_\N(C, p, q, x)) \text{.}
\end{equation*}
For a constant type family we get the non-dependent recursion
\begin{equation*}
\rec_\N(A) :\equiv \ind(\lambda x. A) : A \to (\N \to A \to A) \to \N \to A \text{,}
\end{equation*}
which is exactly the intuitive way to define a function $\N \to A$ by recursion.
If we were to define what it means for a natural number to be odd, we could do
this by
\begin{equation*}
\isodd :\equiv \rec_\N(\UU, \emptytype, (\lambda n. \lambda A. A \to \emptytype)) : \N \to \UU \text{,}
\end{equation*}
where $A \to \emptytype$ is inhabited if $A$ is not, and thus models the negation
of statements.
For example, this gives us the statement that the number one is odd, witnessed by
the following term:
\begin{align*}
(\lambda x. x) :~ & \emptytype \to \emptytype \\
 &\equiv \ind_\N((\lambda x. \UU), \emptytype, (\lambda n. \lambda A. A \to \emptytype), 0)
  \to \emptytype\\
 &\equiv \ind_\N((\lambda x. \UU), \emptytype, (\lambda n. \lambda A. A \to \emptytype), S(0))\\
 &\equiv \isodd(S(0)) \text{.}
\end{align*}

\section{Propositional Equality}

So far, all equalities were judgmental or definitional:
They resulted from defining new notations and from the judgmental equalities that
come with each induction rule.
As mentioned before, it is decidable to check two terms for equality.
But this means that with this kind of equality, we will not be able to reason
about undecidable equality statements, or express equality \emph{inside} the
theory.
Since in the logical interpretation of type theory, every statement should be
represented by a type, so should the equality of two objects of the same type.
This is why we introduce the \textbf{equality type} or \textbf{identity type}
as our next type.
It is obvious that for a type $A : \UU$ and two objects $a, b : A$ there should
be a type $a =_A b$ of which we need so construct an instance to show that $a$
and $b$ are ``equal'' in some sense.
But what should the introduction and the elimination rule for such a type look
like?
It turns out that it should be the relation that is defined inductively on the
witnesses for its reflexivity:
\begin{equation*}
\begin{gathered}
\inferrule*[left={$=$-Form}]{A : \UU \\ a, b : A}{a =_A b : \UU} \qquad
\inferrule*[left={$=$-Intro}]{A : \UU \\ a : A}{\refl_a : a =_A a} \\[.7em]
\inferrule*[left={$=$-Elim}]
	{C : \textstyle{\prod_{(a,b : A)} (a =_A b) \to \UU} \\
		c : \textstyle{\prod_{(a : A)}} C (a, a, \refl_a) \\
		a, b : A \\ p : a =_A b}
	{\ind_{=_A}(C, c, a, b, p) : C(x, y, p)}
\end{gathered}
\end{equation*}
The introduction rule gives us a canonical proof for the equality of two
definitionally equal objects.
The recursor says that to prove a statement about all pairs of points in a type
and all equalities between them, it suffices to show it for reflexive case and
the canonical equality proof $\refl$.
An elimination rule equivalent to the \emph{unbased equality induction} or
\emph{J-rule} stated above is the following \emph{based equality induction} where
we fix the start point of each equality we reason about:
\begin{equation*}
\inferrule*[left={Based-$=$-Elim}]
	{a : A \\ C : \textstyle{\prod_{(b : A)}} (a =_A b) \to \UU \\
		c : C(a, \refl_a) \\
		b : A \\ p : a =_A b}
	{\ind'_{=_A}(a, C, c, b, p) : C(b, p)}
\end{equation*}
Both elimination rules are assumed to yield judgmental equalities when applied
to the constructor $\refl$ itself:
\begin{align*}
\ind_{=_A}(C, c, a, a, \refl_a) &\equiv c(a) \text{ and } \\
\ind'_{=_A}(a, C, c, a, \refl_a) &\equiv c \text{.}
\end{align*}
We will see that for the topological interpretation of types, the identity type
should not necessarily be seen as representing equality of points but rather
\emph{paths between points}.

Equal objects should be indiscernible in the sense that every property $C : A \to \UU$
that is provable for some $a : A$ by giving an instance of $C(a)$ should also be
provable for $b : A$, given an equality $p : a =_A b$.
As a first lemma about equality we prove that this is indeed the case.
(Note that the distinction between a definition and a lemma or theorem together
with its proof is less clear in type theory than it is for set based mathematics.)

\begin{lemma}[Transport] \label{thm:transport-hott}
Let $A : \UU$ be a type, $C : A \to \UU$ a type family, and $a , b : A$ be equal by $p : a =_A b$.
Then, for each $c : C(a)$, we obtain an object $p_*(c) : C(b)$.
We call this the \textbf{transport} of $c$ along the path $p$.
\end{lemma}

\begin{proof}
We can use (based or unbased) path induction to reduce the statement to the one
where $p \equiv \refl_a$.
In this case, we simply to chose $p_*(c) :\equiv c$.
Formally, we define
\begin{equation*}
p_*(c) :\equiv \ind'_{=_A}(a, (\lambda b. \lambda p. C(b)), c, b, p) \text{.}
\end{equation*}
\end{proof}
In the statement of this lemma, like in all the following,
the list of preconditions should be thought of as
an iterated $\Pi$-type, so that the full statement is of the type
\begin{equation*}
\prod_{C : A \to \UU} ~ \prod_{a, b : A} ~ \prod_{p : a =_A b} C(a) \to C(b) \text{.}
\end{equation*}

We have seen that the propositional equality we defined above is, by its constructor
reflexive.
But since equality should be an equivalence relation, we have to prove its
symmetry and transitivity, or, in the language of paths, provide the inverse and
concatenation of paths.

\begin{defn}[Inverse paths]
Let $A : \UU$ and $a, b : A$.
For every path $p : a =_A b$, there is a path $p\inv : b =_A a$ such that
$\refl_a\inv \equiv \refl_a$ for every $a : A$.
\end{defn}

\begin{proof}
By path induction, it suffices to provide $\refl_a\inv : a =_A a$, which we provide
by giving $\refl_a$ itself.
Formally:
$p\inv :\equiv \ind'_{=_A}(a, (\lambda b. \lambda p. b =_A a), \refl_a, b, p)$.
\end{proof}

\begin{defn}[Concatenation of paths]
For a type $A : \UU$, $a, b, c : A$ and paths $p : a = b$ and $q : b = c$ there
is a path $p \ct q : a = c$ which can be chosen in a way such that
$\refl_a \ct \refl_a \equiv \refl_a$.
\end{defn}

\begin{proof}
We again apply induction on the equalities involved to end up having only to
specify an instance of $a = a$ which we choose to be $\refl_a$.
I will from now on abstain from giving the type families and applications
of the equality elimination rule explicitly.
More formal proofs for these definitions can be found in any formalization or
in the HoTT book~\cite{hottbook}.
\end{proof}

We see that this inversion and concatenation are exactly the operations which are
part of a groupoid.
It turns out that they also fulfill the defining properties of a groupoid:

\begin{defn}[Groupoid laws]
Let $A : \UU$, $a, b, c, d : A$ and $p : a = b$, $q : b = c$ and $r : c = d$.
Then,
\begin{itemize}
\item $p = p \ct \refl_b = \refl_a \ct p$,
\item $p\inv \ct p = \refl_b$, $p \ct p\inv = \refl_a$,
\item $(p\inv)\inv = p$ and
\item $p \ct (q \ct r) = (p \ct q) \ct r$.
\end{itemize}
\end{defn}

\begin{proof}
We can prove all these by applying path induction to all the three paths involved.
\end{proof}

Note that all these propositional equalities are \emph{between equalities}. For example,
if we wrote the first equation mentioned in the previous definition noting the
type it was in, it would be $p =_{a =_A b} p \ct \refl_b$.
We call these equalities \textbf{2-paths} or \textbf{2-dimensional paths}.
These make the equality in a type an $\infty$-groupoid.

To be a suitable notion of equality, it should be respected by functions in the
sense that for a function $f : A \to B$ and an equality $p : a = b$ in its domain
we should be able to obtain an equality $f(a) = f(b)$ in the codomain.
This is indeed the case, which we can prove by induction on the equality:
\begin{lemma}
Let $A, B : \UU$, $f : A \to B$, and $a, b : A$. Then, there is a function
$\ap_f : (a = b) \to (f(a) = f(b))$ such that $\ap_f(\refl_a) \equiv \refl_{f(a)}$.
\hfill $\square$
\end{lemma}

We call $\ap_f$ the application of $f$ on paths. $\ap$ is functorial with respect
to the path in the sense that it respects the concatenation and inversion of
paths, and with respect to the function by respecting composition of functions
and acting neutral on the identity function.

\begin{lemma}
Let $A, B, C : \UU$, $f : A \to B$ and $g : B \to C$. For paths $p : a =_A b$ and
$q : b =_A c$ we have equalities
\begin{itemize}
\item $\ap_f(p \ct q) = \ap_f(p) \ct \ap_f(q)$,
\item $\ap_f(p\inv) = \ap_f(p)\inv$,
\item $\ap_g(\ap_f(p)) = \ap_{g \circ f}(p)$, and
\item $\ap_{\id_A}(p) = p$. \hfill $\square$
\end{itemize}
\end{lemma}

But what if $f$ is a dependent function? Then, the $f(a)$ and $f(b)$ would not
necessarily be instances of the same type and so $f(a) = f(b)$ would not be a
valid type.
But we can use the transport (Lemma~\ref{thm:transport-hott}) to turn $f(a)$ into
a point in the same fiber as $f(b)$.

\begin{lemma} \label{thm:apd-hott}
Let $A : \UU$, $P : A \to \UU$ and $f : \prod_{(a : A)} P(a)$. Then, we can construct
a dependent function
\begin{equation*}
\apd_f : \prod_{a, b : A} ~ \prod_{p : a = b} (p_*(f(a)) = f(b)) \text{,}
\end{equation*}
such that $\apd_f(a, a, \refl_a) \equiv \refl_{f(a)}$. \hfill $\square$
\end{lemma}

\section{Equivalences and Univalence}

In set based mathematics we clearly do not care about whether two proofs for the
equality of two elements are themselves equal or not.
Different from that, in the topological setting, where equalities correspond to
paths and equalities between equalities correspond to \emph{homotopies} between
paths, we might want to consider types, where not all paths are homotopic.
But what about equalities between types?
From the logical viewpoint, a good notion of equality would be the \emph{biconditional}:
Two statements $A, B : \UU$ should be equal, if and only if we can find
instances of $A \to B$ and $B \to A$.
A notion of equality for sets, which is weaker than definitional equality, would
be their isomorphicness in the category of sets --- that is, finding a bijection
between them.
When talking about the homotopy type of a topological space however, spaces are
considered equivalent, and their homotopy type equal, when they are \emph{homotopy
equivalent}.
There is a notion of equivalence that captures all these three viewpoints.
To formulate it, we first need the definition of homotopic functions, as known
from classic homotopy theory:

\begin{defn}[Homotopy of functions] \label{def:htpy-hott}
Two maps $f, g : A \to B$ are called \textbf{homotopic} if for all $a : A$ we have
$f(a) = g(a)$.
We define the notation
\begin{equation*}
f \sim g :\equiv \prod_{a : A} (f(a) = g(a)) \text{.}
\end{equation*}
We can define the same for two dependent functions $f, g : \prod_{(a : A)} B(a)$
over the same type family.
\end{defn}

\begin{defn}[Equivalences] \label{def:ishae-hott}
Let $A, B : \UU$. A function $f : A \to B$ is called an \textbf{equivalence}
between $A$ and $B$, if there is a $g : B \to A$ such that
$\eta : g \circ f \sim \id_A$ and $\epsilon : f \circ g \sim \id_B$ and furthermore
\begin{equation*}
\tau : \prod_{a : A} \ap_f(\eta(a)) =_{f(g(f(a)))=a} \epsilon(f(a)) 
 \equiv \ap_f \circ \eta \sim \epsilon \circ f \text{.}
\end{equation*}
We need $\tau$ to make sure that each two witnesses $f$ is an equivalence are
equal.
Since $\tau$ looks like the one of the two commutativity conditions for pairs
of adjoint functors, this kind of equivalence is also called a \textbf{half
adjoint equivalence}.
The type of witnesses for $f$ to be an equivalence shall be
\begin{equation*}
\isequiv(f) :\equiv \sum_{g : B \to A} ~ \sum_{\eta : g \circ f \sim \id_A} ~
\sum_{\epsilon : f \circ g \sim \id_B} \ap_f \circ \eta \sim \epsilon \circ f \text{.}
\end{equation*}
The type of all equivalences between two types $A, B : \UU$ is denoted by
\begin{equation*}
A \simeq B :\equiv \sum_{f : A \to B} \isequiv(f) \text{.}
\end{equation*}
\end{defn}

It is an easy exercise to show that equivalence of types is indeed an equivalence
relation. $\isequiv(f)$ itself is equivalent to other known definitions of equivalence,
like for example the existence of a left inverse and of a right inverse of $f$.
Easy examples for equivalent types include $(\unit \times A) \simeq A$,
$(\unit \to A) \simeq A$, $(\emptytype + A) \simeq A$ and
$(\emptytype \times A) \simeq \emptytype$, for a type $A : \UU$.

But how do equality and equivalence of types relate to each other?
Clearly equal types can be proven to be equivalent, just using path induction
on the equality between them and the reflexivity of equivalence:
\begin{lemma} \label{thm:idtoeqv-hott}
Let $A, B : \UU$. Then there is a function
\begin{equation*}
\idtoeqv_{A, B} : (A =_{\UU} B) \to (A \simeq B) \text{,}
\end{equation*}
which for the reflexivity on $\UU$ is defined by
\begin{equation*}
\idtoeqv_{A,A} (\refl_A) \equiv (\id_A, \id_A, (\lambda a. \refl_a), (\lambda a. \refl_a),
(\lambda a. \refl_{\refl_a})) \text{.}
\end{equation*}
\hfill $\square$
\end{lemma}

On the other hand, there is no way to obtain an equality of types from an equivalence.
Vladimir Voevodsky proposed the following axiom to make it possible:
\begin{axiom}[Univalence]
For $\idtoeqv_{A, B}$ is itself an equivalence for every choice of $A, B : \UU$.

This implies that
\begin{equation*}
(A =_\UU B) \simeq (A \simeq B)
\end{equation*}
and yields an inverse to $\idtoeqv_{A, B}$ which we call
\begin{equation*}
\ua_{A, B} : (A \simeq B) \to (A =_\UU B) \text{.}
\end{equation*}
\end{axiom}

From now on, we will always assume this axiom since as it is essential for the existence
of higher types and thus for homotopy type theory in general.
Another important consequence of assuming univalence is that we can prove
the equality of two dependent functions by giving a homotopy between them:
\begin{thm} \label{thm:funext-hott}
Let $A : \UU$, $B : A \to \UU$ and $f, g : \prod_{(a : A)} B(a)$. Then,
\begin{equation*}
(f \sim g) \to (f =_{A \to B} g) \text{.}
\end{equation*}
\end{thm}
We omit the non-trivial proof for this theorem and refer to the slightly distinct
approaches in the HoTT book~\cite{hottbook} and the Lean library.

\section{Truncated Types}

As already considered in the previous sections, every type $A : \UU$ comes with
a type of paths $a =_A b$ for each $a, b : A$ and iterated, higher dimensional
paths between these paths.
Sometimes we want a type to not contain any information in higher paths by assuming
that all its $n$-dimensional paths are equal.
This leads to the concept of \textbf{truncated types}.

The first definition shall describe what it means for a type to contain only one
point.
We already defined the unit type $\unit$ as the type with exactly one constructor,
but we want a property that we can check for any given type.
This property will then be, as a type, equivalent to being equivalent to the unit
type.
When thinking about types in the logical context, this should remind the reader
of the fact that a true statement which does not depend on any free variables,
is logically equivalent to the canonical ``true'' statement.
In topology, spaces that are homotopy equivalent to a single point are called
contractible.
They are equivalently characterized as those spaces which contain a point serving
as \emph{center} for a contraction --- that is, a continuous choice of paths from each
point in the space to the center.
This is the definition of contractibility which is directly translated to
its counterpart in homotopy type theory:
\begin{defn}[Contractibility]
A type $A : \UU$ is called \textbf{contractible} if
\begin{equation*}
\isContr(A) :\equiv \sum_{x : A} ~ \prod_{a : A} (a =_A x) \text{.}
\end{equation*}
\end{defn}

Analyzing this definition, we first observe that a contractible type is inhabited
by $\pr_1(\isContr(A))$ and that for each $a, b : A$ we can find a path between
$a$ and $b$ by
\begin{equation*}
\pr_2(\isContr(A))(a) \ct \pr_2(\isContr(A))(b)\inv : a =_A b \text{.}
\end{equation*}
This equality of all objects in contractible types makes them the class of types
we want to use for \emph{true propositions}.
As mentioned above, contractible types are equivalent to the unit type:

\begin{lemma}
Let $A : \UU$ be a contractible type. Then, $A \simeq \unit$.
\end{lemma}

\begin{proof}
Let $p : \isContr(A)$.
We obtain a function $f : A \to \unit$ by setting $f(a) :\equiv \star$ for each
$a : A$ and its inverse $g : \unit \to A$, which by induction we only have to
define on the constructor of $\unit$, by $g(\star) :\equiv \pr_1(p)$.
The proof that $f$ and $g$ are indeed inverse to each other is then done
using induction on the unit type and the paths yielded by $\pr_2(p)$.
\end{proof}

If we want to build a class for all propositions, whether true or not, we can use
this consequence of contractibility as a definition and remove the inhabitedness
condition:
\begin{defn}[Mere proposition]
A type $A : \UU$ is a \textbf{mere proposition} if
\begin{equation*}
\isProp(A) :\equiv \prod_{a, b : A} (a =_A b) \text{.}
\end{equation*}
\end{defn}

Besides all contractible types, more concrete examples for mere propositions are $\emptytype$, 
$\unit$, function types with merely propositional codomains, and many of the
defined properties like being an equivalence $\isequiv(f)$, being a contractible
type $\isContr(A)$ and even being a mere proposition $\isProp(A)$.
In the definition of equivalence, the coherence condition $\tau$ is needed
to make it a mere proposition.
Examples for types which are not mere propositions are also easy to find:
$A + B$, whenever $A$ and $B$ are both non-empty types, and $\mathbb{N}$ clearly
contain non-equal objects.

Since the proof that two functions are inverses of each is trivial on a pair of
mere propositions, function types on mere propositions works just as one would
expect from propositions:
\begin{lemma}
Let $A, B : \UU$ be mere propositions and $f : A \to B$, $g : B \to A$.
Then, $A \simeq B$. \hfill $\square$
\end{lemma}

When dealing with sets, we do not require all their objects to be equal, but
only the proofs of equality:
\begin{defn}[Sets]
A type $A : \UU$ is called a \textbf{set}, if there is an object in
\begin{equation*}
\isSet(A) :\equiv \prod_{a, b : A} ~ \prod_{p, q : a =_A b} (p =_{a =_A b} q) \text{.}
\end{equation*}
\end{defn}

So far most types we encountered were sets, but we can use univalence to show
that each of our universes is an example for a type that is not a set:
\begin{lemma}
For each $i$, the universe $\UU_i$ is not a set.
\end{lemma}

\begin{proof}
Consider the type $\twotype :\equiv \unit + \unit : \UU_i$ and let
$0_\twotype :\equiv \inl(\star)$ and $1_\twotype :\equiv \inr(\star)$ be its
two constructors.
As true for every (non-higher) inductive type with multiple constructors,
distinct constructors are unequal:
\begin{equation*}
(0_\twotype \neq 1_\twotype) \equiv (0_\twotype = 1_\twotype \to \emptytype) \text{.}
\end{equation*}
We define a function $f : \twotype \to \twotype$ by setting $f(0_\twotype) :\equiv 1_\twotype$
and $f(1_\twotype) :\equiv 0_\twotype$.
It's easy to see that $f$, as an involution, is an equivalence, which, by univalence
results in a path $p : \twotype =_{\UU_i} \twotype$.
If we assume $\UU_i$ to be a set, we receive an equality $p = \refl_\twotype$.
But transporting along that equality, $f$ would be equal to $\id_\2$ and thus
\begin{equation*}
0_\twotype = f(1_\twotype) = \id_2(1_\twotype) = 1_\twotype \text{,}
\end{equation*}
which, with the above inequality gives the desired result.
\end{proof}

Just like $\isContr(A)$ and $\isProp(A)$, $\isSet(A)$ itself is a mere proposition.
We can also prove that each mere proposition is a set, by which we get
\begin{equation*}
\isContr(A) \to \isProp(A) \to \isSet(A)
\end{equation*}
for each type $A : \UU$. Calling a set a 0-type, a mere proposition a $(-1)$-type
and a contractible type a $(-2)$-type, we can extend this chain by the following
definition of an arbitrary $n$-type or $n$-truncated type:
\begin{defn}[Truncated types]
By recursion on the index we define $\isntype{n}$ as a function $\UU \to \UU$ by
\begin{equation*}
\isntype{n}(A) :\equiv \begin{cases}
\isContr(A) & \text{if $n = -2$ and} \\
\prod_{(a, b, : A)} \isntype{n'}(a =_A b) & \text{if $n = n' + 1$ otherwise.}
\end{cases}
\end{equation*}
\end{defn}

For example, for $n = 1$ this yields
\begin{equation*}
\isntype{1}(A) \simeq \prod_{a, b : A} ~ \prod_{p, q : a =_A b}
	~ \prod_{\alpha, \beta : p =_{a =_A b} q} (\alpha =_{p =_{a =_A b} q} \beta) \text{.}
\end{equation*}

Collecting basic facts about $n$-types, we have
\begin{lemma}
\begin{itemize}
\item If $A : \UU$ is an $n$-type, then $A$ is an $(n+1)$-type.
\item For each $n \geq -2$ and $A : \UU$, the type $\isntype{n}(A)$ is a mere
proposition.
\item If $A : \UU$ is an $n$-type and $B : A \to \UU$ such that for each $a : A$,
$B(a)$ is an $n$-type, then $\sum_{(a : A)} B(a)$ is an $n$-type as well.
\item If $A : \UU$ and $B : A \to \UU$ are such that $B(a)$ is an $n$-type for each
$a : A$, then $\prod_{(a : A)} B(a)$ is an $n$-type as well.
\item Let $n \geq -1$. Then, $A : \UU$ is an $(n+1)$-type if and only if for all $a : A$,
the equality type $a =_A a$ is an $n$-type.
\item Let $n \geq 0$. Then, $A : \UU$ is an $n$-type, if and only if for all $a : A$,
the \emph{$n$-fold iterated loop space} $\Omega^{n+1}(A, a)$, which is defined using
recursion on $n$ by
\begin{align*}
\Omega^1(A, a) &:\equiv (a =_A a) \text{ and}\\
\Omega^{n+1}(A, a) &:\equiv (\refl_{\ddots_a} =_{\Omega^n(A,a)} \refl_{\ddots_a}) \text{,}
\end{align*}
is contractible.
\end{itemize}
\end{lemma}

\section{Higher Inductive Types}

Besides ``normal'' inductive types, which have constructors that objects of or
functions to the type, there is the concept of a \textbf{higher inductive type}.
Higher inductive types can also contain constructors which do not yield instances
of the type itself, but instead propositional equalities between instances.
Like for basic inductive types, I will abstain from giving rules for general
higher inductive type but instead we will take a look at some common higher inductive
types.

We can picture the path constructors as \emph{gluing} a pair of other constructors
together by a new path.
One of the simplest examples for such a case is the one where the type is constructed
by just two instances $0_I$ and $1_I$, together with a path $\seg : 0_I = 1_I$.
The inference rules for this \textbf{interval type} $I$ are the following:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$I$-Form]{ }{I : \UU} \qquad
\inferrule*[left=$I$-Intro1]{ }{0_I : I} \qquad
\inferrule*[left=$I$-Intro2]{ }{1_I : I} \qquad
\inferrule*[left=$I$-Intro3]{ }{\seg : 0_I = 1_I} \\[.7em]
\inferrule*[left=$I$-Elim]
	{C : I \to \UU \\ c_0 : C(0_I) \\ c_1 : C(1_I) \\ p : \seg_*(c_0) = c_1 \\ x : I}
	{\ind_I(C, c_0, c_1, p, x) : C(x)}
\end{gathered}
\end{equation*}
Of course, we again get judgmental equalities for the case where $x$ is one of the
constructors.
As a suitable counterpart for the third constructor, we assume that $\apd_f(seg) = s$,
using the dependent application defined in \ref{thm:apd-hott}, where
$f(x) :\equiv \ind_I(C, c_0, c_1, p, x)$.

In words, to prove a statement for an arbitrary point on the interval, one has
to prove it for both endpoints and show that the proofs can be connected by a
path ``over'' $\seg$.
In the case of the non-dependent recursor, the transport is not necessary.
The type $I$ is a very uninteresting type because of the following:
\begin{lemma}
The interval $I$ is contractible, and therefore $I \simeq \unit$. \hfill $\square$
\end{lemma}

It turns out that if we don't assume the path to be between to distinct constructor
instances but instead be a \emph{loop} based in a single constructor we obtain
the homotopy type $\Sph^1$ of a \textbf{circle} or \textbf{1-sphere}:
\begin{equation*}
\begin{gathered}
\inferrule*[left=$\Sph^1$-Form]{ }{\Sph^1 : \UU} \qquad
\inferrule*[left=$\Sph^1$-Intro1]{ }{\Sbase : \Sph^1} \qquad
\inferrule*[left=$\Sph^1$-Intro2]{ }{\Sloop : \Sbase =_{\Sph^1} \Sbase} \\[.7em]
\inferrule*[left=$\Sph^1$-Elim]
	{C : \Sph^1 \to \UU \\ c : C(\Sbase) \\ p : \Sloop_*(c) = c \\ x : \Sph^1}
	{\ind_{\Sph^1}(C,c,p,x) : C(x)}
\end{gathered}
\end{equation*}

Topologically speaking, the elimination rule tells us that we can find all sections
of a fibration above the circle up to homotopy by appending ``constant sections''
to paths that only lie in one fiber.
Again, if we take $C$ to be the constant type family, we obtain a non-dependent
recursor that lets us define a function $f : \Sph^1 \to B$ by providing
a point $b$, which becomes $f(\Sbase)$ and a loop $b =_B b$ which is propositionally
equal to $\ap_f(\Sloop)$.

We can show that $\Sloop \neq \refl_\Sbase$ and thus, $\Sph^1$ provides another
example for a type which is not a set.
Just as we used the type $\twotype$, which is not a mere proposition,
to show that its surrounding universe is not a set, we can show that a universe
which contains the circle cannot be a 1-type.
We can continue this correspondence by introducing higher dimensional spheres.
As is topology, they can be built as the \textbf{suspension} of a lower dimensional
sphere.
Since suspension is an important operation, especially for homology, we define
it as a type former on arbitrary types (its notation $\Sigma$ should not be confused
with the notation for the type of dependent paris):
\begin{equation*}
\begin{gathered}
\inferrule*[left=Susp-Form]{A : \UU}{\Sigma A : \UU} \qquad
\inferrule*[left=Susp-Intro1]{A : \UU}{N : \Sigma A} \qquad
\inferrule*[left=Susp-Intro2]{A : \UU}{S : \Sigma A} \\[.7em]
\inferrule*[left=Susp-Intro3]{A : \UU}{\Smerid : A \to N =_{\Sigma A} S} \\[.7em]
\inferrule*[left=Susp-Elim]
	{C : \Sigma A \to \UU \\ n : C(N) \\ s : C(S) \\
		m : \textstyle{\prod_{(a : A)} \Smerid(a)_*(n) =_{C(S)} s } \\ x : \Sigma A}
	{\ind_{\Sigma A}(C,n,s,m,x) : C(x)}
\end{gathered}
\end{equation*}

We have judgmental equalities for the point constructors and a propositional
equality to $\apd$ for the path constructor as in the previous examples.
It's an easy task to prove that $\Sigma \twotype \simeq \Sph^1$
which leads us to defining
\begin{align*}
\Sph^0 &:\equiv \twotype \text{ and} \\
\Sph^{n+1} &:\equiv \Sigma \Sph^n
\end{align*}
recursively. For each $n : \N$, the type $S^{n+1}$ is not an $n$-type, the 2-sphere,
for example, is not truncated at any level.

Other important topological operations like pushouts, quotients, and colimits
can be defined in a similar way.
When using higher types we often want to make a type $n$-truncated for some $n$
by ``collapsing'' all equalities above dimension $n$ while preserving its properties
below that level.
This operation is called $n$\textbf{-truncation} and is defined by the following
formation, introduction and elimination rules:
\begin{equation*}
\begin{gathered}
\inferrule*[left=Trunc-Form]{A : \UU \\ n : \N}{\trunc{n}{A} : \UU} \qquad
\inferrule*[left=Trunc-Intro]{a : A}{\left| a \right|_n : \trunc{n}{A}} \\[.7em]
\inferrule*[left=Trunc-Elim]
	{C : \trunc{n}{A} \to \UU \\
		p : \textstyle{ \prod_{(x : \trunc{n}{A})} \isntype{n}(C(x)) } \\
		g : \textstyle{ \prod_{(a : A)} P(\left| a \right|_n) } \\
		x : \trunc{n}{A}}
	{\ind_{\trunc{n}{A}}(C,p,g,x) : C(x)}
\end{gathered}
\end{equation*}

As one can easily derive from the elimination rule, $\trunc{n}{A}$ is an $n$-type
and, together with the introduction rule, we can prove that every map in
$A \to B$, for an $n$-type $B$, factors through $\trunc{n}{A}$ by $\left| \cdot \right|_n$
and $\ind_{\trunc{n}{A}}$.

Of course there are many interactions between all the elements of homotopy type
theory that were introduced in this chapter.
A deeper analysis of these can be found in the HoTT book~\cite{hottbook} as
well as in many subsequent publications.
This introduction should suffice to give enough understanding for the reader
to know all definitions used in Chapter \ref{chapter:types}.
Describing the general syntax and semantics of higher inductive types still
remains an open problem.


